{
  "game_record": {
    "game_id": "20250912-104249",
    "timestamp": "2025-09-12T10:42:49.737962",
    "topic_category": "elo_2_kimik2_gptoss_qwen3_DS3.1",
    "concept_pair": {
      "concept_a": "chair",
      "concept_b": "table"
    },
    "judges": [
      {
        "id": "claude-3-7-sonnet-20250219",
        "version": ""
      },
      {
        "id": "gpt-4.1",
        "version": ""
      }
    ],
    "players": [
      {
        "player_id": 1,
        "llm_id": "deepseek-v3.1",
        "role": "civilian",
        "assigned_concept": "chair",
        "eliminated_in_voting_round": null,
        "is_winner": true
      },
      {
        "player_id": 2,
        "llm_id": "deepseek-v3",
        "role": "civilian",
        "assigned_concept": "chair",
        "eliminated_in_voting_round": null,
        "is_winner": true
      },
      {
        "player_id": 3,
        "llm_id": "qwen2.5-72b",
        "role": "civilian",
        "assigned_concept": "chair",
        "eliminated_in_voting_round": null,
        "is_winner": true
      },
      {
        "player_id": 4,
        "llm_id": "qwen-plus-2025-04-28",
        "role": "undercover",
        "assigned_concept": "table",
        "eliminated_in_voting_round": -1,
        "is_winner": false
      },
      {
        "player_id": 5,
        "llm_id": "kimi-k2-instruct",
        "role": "undercover",
        "assigned_concept": "table",
        "eliminated_in_voting_round": 1,
        "is_winner": false
      },
      {
        "player_id": 6,
        "llm_id": "gpt-oss-120b",
        "role": "civilian",
        "assigned_concept": "chair",
        "eliminated_in_voting_round": null,
        "is_winner": true
      }
    ],
    "game_process": {
      "statements": [
        {
          "statement_id": 1,
          "player_id": 1,
          "llm_id": "deepseek-v3.1",
          "content": "It's a common piece of furniture designed for sitting.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 1.0,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 1.0
              },
              "relevance_score_mean": 0.9,
              "relevance_score_variance": 0.009999999999999995,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1": 1.0
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 1.0
              }
            }
          }
        },
        {
          "statement_id": 2,
          "player_id": 2,
          "llm_id": "deepseek-v3",
          "content": "It often has four legs and a backrest for support.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.8,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1": 0.8
              },
              "relevance_score_mean": 0.9,
              "relevance_score_variance": 0.009999999999999995,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 1.0
              }
            }
          }
        },
        {
          "statement_id": 3,
          "player_id": 6,
          "llm_id": "gpt-oss-120b",
          "content": "Often placed around a desk or table for work or meals.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.9,
              "novelty_score_variance": 0.009999999999999995,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 0.8
              },
              "relevance_score_mean": 0.8,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 1.0
              }
            }
          }
        },
        {
          "statement_id": 4,
          "player_id": 4,
          "llm_id": "qwen-plus-2025-04-28",
          "content": "",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0,
                  "relevance_score": 0,
                  "reasonableness_score": 0
                }
              },
              {
                "judge_id": "gpt-4.1",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0,
                  "reasonableness_score": 0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.5,
              "novelty_score_variance": 0.25,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0,
                "gpt-4.1": 1.0
              },
              "relevance_score_mean": 0.0,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0,
                "gpt-4.1": 0
              },
              "reasonableness_score_mean": 0.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 0,
                "gpt-4.1": 0
              }
            }
          }
        },
        {
          "statement_id": 5,
          "player_id": 5,
          "llm_id": "kimi-k2-instruct",
          "content": "It usually offers a flat surface supported by four legs.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 1.0,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 1.0
              },
              "relevance_score_mean": 0.9,
              "relevance_score_variance": 0.009999999999999995,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 1.0
              }
            }
          }
        },
        {
          "statement_id": 6,
          "player_id": 3,
          "llm_id": "qwen2.5-72b",
          "content": "It can be found in various settings, from homes to offices and public spaces.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.2,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1",
                "metrics": {
                  "novelty_score": 0.6,
                  "relevance_score": 0.4,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.8,
              "novelty_score_variance": 0.04000000000000001,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 0.6
              },
              "relevance_score_mean": 0.30000000000000004,
              "relevance_score_variance": 0.010000000000000002,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.2,
                "gpt-4.1": 0.4
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1": 1.0
              }
            }
          }
        }
      ],
      "voting_rounds": [
        {
          "voting_round_id": 1,
          "after_statement_round": 1,
          "after_statement_id": 6,
          "votes": [
            {
              "voter_id": 1,
              "voted_for": 3
            },
            {
              "voter_id": 2,
              "voted_for": 6
            },
            {
              "voter_id": 3,
              "voted_for": 5
            },
            {
              "voter_id": 5,
              "voted_for": 6
            },
            {
              "voter_id": 6,
              "voted_for": 5
            }
          ],
          "vote_results": {
            "1": 0,
            "2": 0,
            "3": 1,
            "5": 2,
            "6": 2
          },
          "eliminated": [
            {
              "player_id": 5,
              "llm_id": "kimi-k2-instruct",
              "role": "undercover",
              "correct_elimination": true
            }
          ]
        }
      ],
      "metric_eliminations": [
        {
          "player_id": 4,
          "llm_id": "qwen-plus-2025-04-28",
          "role": "undercover",
          "elimination_round": 1,
          "elimination_reason": "Low reasonableness score: 0.00",
          "metrics": {
            "novelty_mean": 0.5,
            "reasonableness_mean": 0.0
          }
        }
      ]
    },
    "game_summary": {
      "total_statement_rounds": 1,
      "total_voting_rounds": 1,
      "total_statements": 6,
      "winner_role": "civilian",
      "winner_ids": [
        1,
        2,
        3,
        6
      ],
      "correct_identifications": 1,
      "incorrect_identifications": 0,
      "game_decision_quality": 1.0
    },
    "game_analysis": {}
  }
}
{
  "game_record": {
    "game_id": "20250509-163546",
    "timestamp": "2025-05-09T16:35:46.960630",
    "topic_category": "stationary",
    "concept_pair": {
      "concept_a": "eraser",
      "concept_b": "ruler"
    },
    "judges": [
      {
        "id": "claude-3-7-sonnet-20250219",
        "version": ""
      },
      {
        "id": "gpt-4.1-2025-04-14",
        "version": ""
      }
    ],
    "players": [
      {
        "player_id": 1,
        "llm_id": "claude-3-5-haiku-20241022",
        "role": "civilian",
        "assigned_concept": "eraser",
        "eliminated_in_voting_round": null,
        "is_winner": true
      },
      {
        "player_id": 2,
        "llm_id": "gpt-4o-2024-11-20",
        "role": "undercover",
        "assigned_concept": "ruler",
        "eliminated_in_voting_round": 2,
        "is_winner": false
      },
      {
        "player_id": 3,
        "llm_id": "qwen2.5-72b",
        "role": "civilian",
        "assigned_concept": "eraser",
        "eliminated_in_voting_round": null,
        "is_winner": true
      },
      {
        "player_id": 4,
        "llm_id": "llama-3.3-70b-instruct",
        "role": "civilian",
        "assigned_concept": "eraser",
        "eliminated_in_voting_round": null,
        "is_winner": true
      },
      {
        "player_id": 5,
        "llm_id": "gemini-2.0-pro-exp",
        "role": "civilian",
        "assigned_concept": "eraser",
        "eliminated_in_voting_round": null,
        "is_winner": true
      },
      {
        "player_id": 6,
        "llm_id": "deepseek-v3",
        "role": "undercover",
        "assigned_concept": "ruler",
        "eliminated_in_voting_round": 1,
        "is_winner": false
      }
    ],
    "game_process": {
      "statements": [
        {
          "statement_id": 1,
          "player_id": 4,
          "llm_id": "llama-3.3-70b-instruct",
          "content": "It's something that can be found on a desk.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.2,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.2,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 1.0,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              },
              "relevance_score_mean": 0.2,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.2,
                "gpt-4.1-2025-04-14": 0.2
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 2,
          "player_id": 6,
          "llm_id": "deepseek-v3",
          "content": "It's often used to measure or draw straight lines.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.9,
              "novelty_score_variance": 0.009999999999999995,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 0.8
              },
              "relevance_score_mean": 1.0,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 3,
          "player_id": 5,
          "llm_id": "gemini-2.0-pro-exp",
          "content": "It can help correct mistakes.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.9,
              "novelty_score_variance": 0.009999999999999995,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 0.8
              },
              "relevance_score_mean": 0.8,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 4,
          "player_id": 3,
          "llm_id": "qwen2.5-72b",
          "content": "It's a common tool used in writing and drawing.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.6,
                  "relevance_score": 0.2,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.2,
                  "relevance_score": 0.4,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.4,
              "novelty_score_variance": 0.039999999999999994,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.6,
                "gpt-4.1-2025-04-14": 0.2
              },
              "relevance_score_mean": 0.30000000000000004,
              "relevance_score_variance": 0.010000000000000002,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.2,
                "gpt-4.1-2025-04-14": 0.4
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 5,
          "player_id": 2,
          "llm_id": "gpt-4o-2024-11-20",
          "content": "It often has markings for centimeters and inches.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 1.0,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              },
              "relevance_score_mean": 1.0,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 6,
          "player_id": 1,
          "llm_id": "claude-3-5-haiku-20241022",
          "content": "It helps remove unwanted marks or writing from a surface.",
          "statement_round": 1,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.6,
                  "relevance_score": 1.0,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.8,
              "novelty_score_variance": 0.04000000000000001,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 0.6
              },
              "relevance_score_mean": 1.0,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 7,
          "player_id": 5,
          "llm_id": "gemini-2.0-pro-exp",
          "content": "It's typically made of a soft, pliable material.",
          "statement_round": 2,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.8,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "relevance_score_mean": 0.8,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 8,
          "player_id": 3,
          "llm_id": "qwen2.5-72b",
          "content": "It can be used to make things cleaner and neater.",
          "statement_round": 2,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.6,
                  "relevance_score": 0.6,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.6,
                  "relevance_score": 0.6,
                  "reasonableness_score": 0.8
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.6,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.6,
                "gpt-4.1-2025-04-14": 0.6
              },
              "relevance_score_mean": 0.6,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.6,
                "gpt-4.1-2025-04-14": 0.6
              },
              "reasonableness_score_mean": 0.9,
              "reasonableness_score_variance": 0.009999999999999995,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 0.8
              }
            }
          }
        },
        {
          "statement_id": 9,
          "player_id": 2,
          "llm_id": "gpt-4o-2024-11-20",
          "content": "It is often used to ensure precision in tasks.",
          "statement_round": 2,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.6,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.8,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "relevance_score_mean": 0.7,
              "relevance_score_variance": 0.010000000000000005,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.6,
                "gpt-4.1-2025-04-14": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 10,
          "player_id": 1,
          "llm_id": "claude-3-5-haiku-20241022",
          "content": "It helps remove unwanted marks without leaving residue behind.",
          "statement_round": 2,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 0.6,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.6,
                  "relevance_score": 0.8,
                  "reasonableness_score": 1.0
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.6,
              "novelty_score_variance": 0.0,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.6,
                "gpt-4.1-2025-04-14": 0.6
              },
              "relevance_score_mean": 0.8,
              "relevance_score_variance": 0.0,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.8,
                "gpt-4.1-2025-04-14": 0.8
              },
              "reasonableness_score_mean": 1.0,
              "reasonableness_score_variance": 0.0,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 1.0
              }
            }
          }
        },
        {
          "statement_id": 11,
          "player_id": 4,
          "llm_id": "llama-3.3-70b-instruct",
          "content": "It's something that can be easily replaced if it becomes worn out.",
          "statement_round": 2,
          "metrics": {
            "judges_evaluations": [
              {
                "judge_id": "claude-3-7-sonnet-20250219",
                "metrics": {
                  "novelty_score": 1.0,
                  "relevance_score": 0.4,
                  "reasonableness_score": 1.0
                }
              },
              {
                "judge_id": "gpt-4.1-2025-04-14",
                "metrics": {
                  "novelty_score": 0.8,
                  "relevance_score": 0.6,
                  "reasonableness_score": 0.8
                }
              }
            ],
            "judges_stats": {
              "novelty_score_mean": 0.9,
              "novelty_score_variance": 0.009999999999999995,
              "novelty_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 0.8
              },
              "relevance_score_mean": 0.5,
              "relevance_score_variance": 0.009999999999999995,
              "relevance_score_all_values": {
                "claude-3-7-sonnet-20250219": 0.4,
                "gpt-4.1-2025-04-14": 0.6
              },
              "reasonableness_score_mean": 0.9,
              "reasonableness_score_variance": 0.009999999999999995,
              "reasonableness_score_all_values": {
                "claude-3-7-sonnet-20250219": 1.0,
                "gpt-4.1-2025-04-14": 0.8
              }
            }
          }
        }
      ],
      "voting_rounds": [
        {
          "voting_round_id": 1,
          "after_statement_round": 1,
          "after_statement_id": 6,
          "votes": [
            {
              "voter_id": 1,
              "voted_for": 6
            },
            {
              "voter_id": 2,
              "voted_for": 5
            },
            {
              "voter_id": 3,
              "voted_for": 6
            },
            {
              "voter_id": 4,
              "voted_for": 2
            },
            {
              "voter_id": 5,
              "voted_for": 4
            },
            {
              "voter_id": 6,
              "voted_for": 1
            }
          ],
          "vote_results": {
            "1": 1,
            "2": 1,
            "3": 0,
            "4": 1,
            "5": 1,
            "6": 2
          },
          "eliminated": [
            {
              "player_id": 6,
              "llm_id": "deepseek-v3",
              "role": "undercover",
              "correct_elimination": true
            }
          ]
        },
        {
          "voting_round_id": 2,
          "after_statement_round": 2,
          "after_statement_id": 11,
          "votes": [
            {
              "voter_id": 1,
              "voted_for": 6
            },
            {
              "voter_id": 2,
              "voted_for": 5
            },
            {
              "voter_id": 3,
              "voted_for": 2
            },
            {
              "voter_id": 4,
              "voted_for": 2
            },
            {
              "voter_id": 5,
              "voted_for": 1
            }
          ],
          "vote_results": {
            "1": 1,
            "2": 2,
            "3": 0,
            "4": 0,
            "5": 1
          },
          "eliminated": [
            {
              "player_id": 2,
              "llm_id": "gpt-4o-2024-11-20",
              "role": "undercover",
              "correct_elimination": true
            }
          ]
        }
      ]
    },
    "game_summary": {
      "total_statement_rounds": 2,
      "total_voting_rounds": 2,
      "total_statements": 11,
      "winner_role": "civilian",
      "winner_ids": [
        1,
        3,
        4,
        5
      ],
      "correct_identifications": 2,
      "incorrect_identifications": 0,
      "game_decision_quality": 1.0
    },
    "game_analysis": {}
  }
}